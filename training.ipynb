{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device='cuda'\n",
    "else:\n",
    "    device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id1</th>\n",
       "      <th>id2</th>\n",
       "      <th>id3</th>\n",
       "      <th>id4</th>\n",
       "      <th>id5</th>\n",
       "      <th>y</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>...</th>\n",
       "      <th>f28_ctr</th>\n",
       "      <th>f30_ctr</th>\n",
       "      <th>f28_has_impression</th>\n",
       "      <th>f29_has_click</th>\n",
       "      <th>f30_has_impression</th>\n",
       "      <th>f31_has_click</th>\n",
       "      <th>f39_41_total_spend</th>\n",
       "      <th>f39_ratio</th>\n",
       "      <th>f40_ratio</th>\n",
       "      <th>f41_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1366776_189706075_16-23_2023-11-02 22:22:00.042</td>\n",
       "      <td>1366776</td>\n",
       "      <td>189706075</td>\n",
       "      <td>2023-11-02 22:22:00.042</td>\n",
       "      <td>2023-11-02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011613</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1366776_89227_16-23_2023-11-01 23:51:24.999</td>\n",
       "      <td>1366776</td>\n",
       "      <td>89227</td>\n",
       "      <td>2023-11-01 23:51:24.999</td>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012233</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1366776_35046_16-23_2023-11-01 00:30:59.797</td>\n",
       "      <td>1366776</td>\n",
       "      <td>35046</td>\n",
       "      <td>2023-11-01 00:30:59.797</td>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005819</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1366776_6275451_16-23_2023-11-02 22:21:32.261</td>\n",
       "      <td>1366776</td>\n",
       "      <td>6275451</td>\n",
       "      <td>2023-11-02 22:21:32.261</td>\n",
       "      <td>2023-11-02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011613</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1366776_78053_16-23_2023-11-02 22:21:34.799</td>\n",
       "      <td>1366776</td>\n",
       "      <td>78053</td>\n",
       "      <td>2023-11-02 22:21:34.799</td>\n",
       "      <td>2023-11-02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011613</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770159</th>\n",
       "      <td>1896641_87731_16-23_2023-11-02 08:14:21.524</td>\n",
       "      <td>1896641</td>\n",
       "      <td>87731</td>\n",
       "      <td>2023-11-02 08:14:21.524</td>\n",
       "      <td>2023-11-02</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006691</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>318.000000</td>\n",
       "      <td>0.7861</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770160</th>\n",
       "      <td>1896641_505604_16-23_2023-11-02 08:14:24.458</td>\n",
       "      <td>1896641</td>\n",
       "      <td>505604</td>\n",
       "      <td>2023-11-02 08:14:24.458</td>\n",
       "      <td>2023-11-02</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006691</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>318.000000</td>\n",
       "      <td>0.7861</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770161</th>\n",
       "      <td>1896641_25212_16-23_2023-11-02 08:14:25.748</td>\n",
       "      <td>1896641</td>\n",
       "      <td>25212</td>\n",
       "      <td>2023-11-02 08:14:25.748</td>\n",
       "      <td>2023-11-02</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006691</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>318.000000</td>\n",
       "      <td>0.7861</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770162</th>\n",
       "      <td>1900765_95157_16-23_2023-11-02 06:08:25.900</td>\n",
       "      <td>1900765</td>\n",
       "      <td>95157</td>\n",
       "      <td>2023-11-02 06:08:25.900</td>\n",
       "      <td>2023-11-02</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>102.500000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770163</th>\n",
       "      <td>1901215_95807_16-23_2023-11-01 11:01:33.086</td>\n",
       "      <td>1901215</td>\n",
       "      <td>95807</td>\n",
       "      <td>2023-11-01 11:01:33.086</td>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>75.059998</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>770164 rows Ã— 347 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    id1      id2        id3  \\\n",
       "0       1366776_189706075_16-23_2023-11-02 22:22:00.042  1366776  189706075   \n",
       "1           1366776_89227_16-23_2023-11-01 23:51:24.999  1366776      89227   \n",
       "2           1366776_35046_16-23_2023-11-01 00:30:59.797  1366776      35046   \n",
       "3         1366776_6275451_16-23_2023-11-02 22:21:32.261  1366776    6275451   \n",
       "4           1366776_78053_16-23_2023-11-02 22:21:34.799  1366776      78053   \n",
       "...                                                 ...      ...        ...   \n",
       "770159      1896641_87731_16-23_2023-11-02 08:14:21.524  1896641      87731   \n",
       "770160     1896641_505604_16-23_2023-11-02 08:14:24.458  1896641     505604   \n",
       "770161      1896641_25212_16-23_2023-11-02 08:14:25.748  1896641      25212   \n",
       "770162      1900765_95157_16-23_2023-11-02 06:08:25.900  1900765      95157   \n",
       "770163      1901215_95807_16-23_2023-11-01 11:01:33.086  1901215      95807   \n",
       "\n",
       "                            id4         id5  y    f1    f2    f3    f4  ...  \\\n",
       "0       2023-11-02 22:22:00.042  2023-11-02  0     1  <NA>  <NA>  <NA>  ...   \n",
       "1       2023-11-01 23:51:24.999  2023-11-01  0     1  <NA>  <NA>  <NA>  ...   \n",
       "2       2023-11-01 00:30:59.797  2023-11-01  0     1  <NA>  <NA>  <NA>  ...   \n",
       "3       2023-11-02 22:21:32.261  2023-11-02  0     1  <NA>  <NA>  <NA>  ...   \n",
       "4       2023-11-02 22:21:34.799  2023-11-02  0     1  <NA>  <NA>  <NA>  ...   \n",
       "...                         ...         ... ..   ...   ...   ...   ...  ...   \n",
       "770159  2023-11-02 08:14:21.524  2023-11-02  0  <NA>  <NA>  <NA>  <NA>  ...   \n",
       "770160  2023-11-02 08:14:24.458  2023-11-02  0  <NA>  <NA>  <NA>  <NA>  ...   \n",
       "770161  2023-11-02 08:14:25.748  2023-11-02  0  <NA>  <NA>  <NA>  <NA>  ...   \n",
       "770162  2023-11-02 06:08:25.900  2023-11-02  0  <NA>  <NA>  <NA>  <NA>  ...   \n",
       "770163  2023-11-01 11:01:33.086  2023-11-01  0  <NA>  <NA>  <NA>  <NA>  ...   \n",
       "\n",
       "        f28_ctr   f30_ctr  f28_has_impression  f29_has_click  \\\n",
       "0           0.0  0.011613                True          False   \n",
       "1           0.0  0.012233                True          False   \n",
       "2           0.0  0.005819                True          False   \n",
       "3           0.0  0.011613                True          False   \n",
       "4           0.0  0.011613                True          False   \n",
       "...         ...       ...                 ...            ...   \n",
       "770159      0.0  0.006691                True          False   \n",
       "770160      0.0  0.006691                True          False   \n",
       "770161      0.0  0.006691                True          False   \n",
       "770162      0.0  0.000000                True          False   \n",
       "770163      0.0  0.000000                True          False   \n",
       "\n",
       "        f30_has_impression  f31_has_click  f39_41_total_spend  f39_ratio  \\\n",
       "0                     True           True            0.000000     0.0000   \n",
       "1                     True           True            0.000000     0.0000   \n",
       "2                     True           True            0.000000     0.0000   \n",
       "3                     True           True            0.000000     0.0000   \n",
       "4                     True           True            0.000000     0.0000   \n",
       "...                    ...            ...                 ...        ...   \n",
       "770159                True           True          318.000000     0.7861   \n",
       "770160                True           True          318.000000     0.7861   \n",
       "770161                True           True          318.000000     0.7861   \n",
       "770162                True          False          102.500000     0.0000   \n",
       "770163               False          False           75.059998     0.0000   \n",
       "\n",
       "        f40_ratio  f41_ratio  \n",
       "0             0.0     0.0000  \n",
       "1             0.0     0.0000  \n",
       "2             0.0     0.0000  \n",
       "3             0.0     0.0000  \n",
       "4             0.0     0.0000  \n",
       "...           ...        ...  \n",
       "770159        0.0     0.2139  \n",
       "770160        0.0     0.2139  \n",
       "770161        0.0     0.2139  \n",
       "770162        0.0     1.0000  \n",
       "770163        0.0     1.0000  \n",
       "\n",
       "[770164 rows x 347 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\"trainf.parquet\", engine='pyarrow')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_NUMERICAL = [\n",
    "    'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10',\n",
    "    'f11', 'f12', 'f13', 'f18', 'f22', 'f26', 'f27', 'f32', 'f33', 'f35',\n",
    "    'f36', 'f38', 'f39', 'f40', 'f41', 'f43', 'f44', 'f45', 'f46', 'f47',\n",
    "    'f49', 'f51', 'f58', 'f59', 'f68', 'f77', 'f78', 'f79', 'f81', 'f82',\n",
    "    'f83', 'f85', 'f86', 'f87', 'f88', 'f89', 'f90', 'f91', 'f92', 'f93',\n",
    "    'f94', 'f95', 'f96', 'f97', 'f98', 'f99', 'f100', 'f101', 'f102', 'f103',\n",
    "    'f104', 'f105', 'f106', 'f107', 'f108', 'f109', 'f110', 'f111', 'f113', 'f114',\n",
    "    'f115', 'f116', 'f117', 'f118', 'f119', 'f120', 'f121', 'f123', 'f124', 'f125',\n",
    "    'f126', 'f127', 'f128', 'f129', 'f130', 'f131', 'f132', 'f133', 'f134', 'f137',\n",
    "    'f138', 'f139', 'f140', 'f141', 'f142', 'f143', 'f144', 'f145', 'f146', 'f147',\n",
    "    'f148', 'f149', 'f150', 'f151', 'f152', 'f153', 'f154', 'f155', 'f156', 'f157',\n",
    "    'f158', 'f159', 'f160', 'f161', 'f162', 'f163', 'f164', 'f165', 'f166', 'f167',\n",
    "    'f169', 'f170', 'f171', 'f172', 'f173', 'f174', 'f175', 'f176', 'f177', 'f178',\n",
    "    'f179', 'f180', 'f181', 'f182', 'f183', 'f184', 'f185', 'f186', 'f187', 'f188',\n",
    "    'f189', 'f190', 'f191', 'f192', 'f193', 'f194', 'f195', 'f196', 'f197', 'f198',\n",
    "    'f199', 'f200', 'f201', 'f202', 'f203', 'f204', 'f205', 'f206', 'f207', 'f208',\n",
    "    'f209', 'f210', 'f211', 'f212', 'f213', 'f214', 'f215', 'f216', 'f217', 'f219',\n",
    "    'f220', 'f221', 'f222', 'f223', 'f224', 'f225', 'f310', 'f311', 'f312', 'f313',\n",
    "    'f314', 'f315', 'f316', 'f317', 'f318', 'f319', 'f320', 'f321', 'f322', 'f323',\n",
    "    'f324', 'f325', 'f326', 'f327', 'f328', 'f329', 'f330', 'f331', 'f332', 'f333',\n",
    "    'f336', 'f337', 'f338', 'f339', 'f340', 'f341', 'f342', 'f343', 'f344', 'f345',\n",
    "    'f346', 'f347', 'f348', 'f352', 'f353', 'f355', 'f356', 'f357', 'f358', 'f359',\n",
    "    'f360', 'f361', 'f362', 'f363', 'f364', 'f365', 'f366', 'f28_ctr', 'f30_ctr', \n",
    "    'f39_41_total_spend', 'f39_ratio', 'f40_ratio', 'f41_ratio',\n",
    "]\n",
    "\n",
    "USER_CATEGORICAL = [\"f42\", \"f48\", \"f50\", \"f52\", \"f53\", \"f54\", \"f55\", \"f56\", \"f57\"]\n",
    "\n",
    "OFFER_ID = 'id3'\n",
    "\n",
    "OFFER_CONTEXTUAL = [\"f168\", \"f349\", \"f350\", \"f351\", \"f354\"]\n",
    "\n",
    "OFFER_CATEGORIES = [\"f226\", \"f227\", \"f228\", \"f229\", \"f230\", \"f231\", \"f232\"]\n",
    "\n",
    "OFFER_SUBCATEGORIES = [\n",
    "    'f233', 'f234', 'f235', 'f236', 'f237', 'f238', 'f239', 'f240', 'f241', 'f242',\n",
    "    'f243', 'f244', 'f245', 'f246', 'f247', 'f248', 'f249', 'f250', 'f251', 'f252',\n",
    "    'f253', 'f254', 'f255', 'f256', 'f257', 'f258', 'f259', 'f260', 'f261', 'f262',\n",
    "    'f263', 'f264', 'f265', 'f266', 'f267', 'f268', 'f269', 'f270', 'f271', 'f272',\n",
    "    'f273', 'f274', 'f275', 'f276', 'f277', 'f278', 'f279', 'f280', 'f281', 'f282',\n",
    "    'f283', 'f284', 'f285', 'f286', 'f287', 'f288', 'f289', 'f290', 'f291', 'f292',\n",
    "    'f293', 'f294', 'f295', 'f296', 'f297', 'f298', 'f299', 'f300', 'f301', 'f302',\n",
    "    'f303', 'f304', 'f305', 'f306', 'f307', 'f308', 'f309',\n",
    "]\n",
    "\n",
    "OFFER_FEATURES = OFFER_CONTEXTUAL + OFFER_CATEGORIES + OFFER_SUBCATEGORIES\n",
    "\n",
    "\n",
    "INTERACTION_FEATURES = [\n",
    "    \"f28\",  # Cumulative OET offer impressions (with decay)\n",
    "    \"f29\",  # Cumulative OET offer clicks (with decay)\n",
    "    \"f30\",  # Cumulative merchant offer impressions (with decay)\n",
    "    \"f31\",  # Cumulative merchant offer clicks (with decay)\n",
    "    \"f28_has_impression\",  # Boolean: has OET impressions\n",
    "    \"f29_has_click\",       # Boolean: has OET clicks\n",
    "    \"f30_has_impression\",  # Boolean: has merchant impressions\n",
    "    \"f31_has_click\"        # Boolean: has merchant clicks\n",
    "]\n",
    "\n",
    "LABEL = 'y'\n",
    "USER_ID = 'id2'\n",
    "TIMESTAMP = 'id4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep id2 (user_id) for MAP@7 evaluation, drop others\n",
    "user_ids = df['id2'].copy()\n",
    "df.drop(columns=['id1','id2','id4','id5'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_user = {}\n",
    "for col in USER_CATEGORICAL:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "    le_user[col] = le\n",
    "\n",
    "le_offer = LabelEncoder()\n",
    "df[OFFER_ID] = le_offer.fit_transform(df[OFFER_ID].astype(str))\n",
    "num_offers = len(le_offer.classes_)\n",
    "\n",
    "\n",
    "for col in USER_NUMERICAL:\n",
    "    if df[col].dtype in ['Int8', 'Int16', 'Int32', 'int64']:\n",
    "        df[col] = df[col].fillna(0).astype('float32')\n",
    "    elif df[col].dtype == 'bool':\n",
    "        df[col] = df[col].fillna(False).astype('float32')\n",
    "    elif df[col].dtype == 'float32':\n",
    "        df[col] = df[col].fillna(0.0)\n",
    "\n",
    "# Scale user numerical features\n",
    "scaler_user = StandardScaler()\n",
    "df[USER_NUMERICAL] = scaler_user.fit_transform(df[USER_NUMERICAL])\n",
    "\n",
    "# Replace any remaining inf/nan after scaling\n",
    "df[USER_NUMERICAL] = df[USER_NUMERICAL].replace([np.inf, -np.inf], 0)\n",
    "df[USER_NUMERICAL] = df[USER_NUMERICAL].fillna(0)\n",
    "\n",
    "# Convert interaction features to float (handle bool and nullable ints)\n",
    "for col in INTERACTION_FEATURES:\n",
    "    if df[col].dtype in ['Int8', 'Int16', 'Int32', 'int64']:\n",
    "        df[col] = df[col].fillna(0).astype('float32')\n",
    "    elif df[col].dtype == 'bool':\n",
    "        df[col] = df[col].fillna(False).astype('float32')\n",
    "    elif df[col].dtype == 'float32':\n",
    "        df[col] = df[col].fillna(0.0)\n",
    "\n",
    "# Define feature columns\n",
    "user_features_cols = USER_NUMERICAL + USER_CATEGORICAL\n",
    "offer_id_col = OFFER_ID\n",
    "cat_features_cols = INTERACTION_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN in df: 1194516\n",
      "Inf in user numerical: 0\n",
      "Label distribution: y\n",
      "0    733113\n",
      "1     37051\n",
      "Name: count, dtype: int64\n",
      "Label dtype: int64\n",
      "Sample labels: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN and inf values\n",
    "print(f\"NaN in df: {df.isna().sum().sum()}\")\n",
    "print(f\"Inf in user numerical: {np.isinf(df[USER_NUMERICAL].values).sum()}\")\n",
    "print(f\"Label distribution: {df[LABEL].value_counts()}\")\n",
    "print(f\"Label dtype: {df[LABEL].dtype}\")\n",
    "print(f\"Sample labels: {df[LABEL].head(20).tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with NaN: ['f22_others', 'f168', 'f218', 'f351', 'f354']\n",
      "Total columns with NaN: 5\n",
      "\n",
      "NaN in USER_NUMERICAL: 0\n",
      "NaN in USER_CATEGORICAL: 0\n",
      "NaN in INTERACTION_FEATURES: 0\n"
     ]
    }
   ],
   "source": [
    "# Check which columns still have NaN\n",
    "nan_cols = df.columns[df.isna().any()].tolist()\n",
    "print(f\"Columns with NaN: {nan_cols[:20]}\")\n",
    "print(f\"Total columns with NaN: {len(nan_cols)}\")\n",
    "\n",
    "print(f\"\\nNaN in USER_NUMERICAL: {df[USER_NUMERICAL].isna().sum().sum()}\")\n",
    "print(f\"NaN in USER_CATEGORICAL: {df[USER_CATEGORICAL].isna().sum().sum()}\")\n",
    "print(f\"NaN in INTERACTION_FEATURES: {df[INTERACTION_FEATURES].isna().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[user_features_cols + [offer_id_col] + cat_features_cols]\n",
    "y = df[LABEL]\n",
    "X_train, X_test, y_train, y_test, user_train, user_test = train_test_split(\n",
    "    X, y, user_ids, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, user_features, offer_ids, cat_features, labels):\n",
    "        self.user_features = torch.tensor(user_features.values, dtype=torch.float32)\n",
    "        self.offer_ids = torch.tensor(offer_ids.values, dtype=torch.long)\n",
    "        self.cat_features = torch.tensor(cat_features.values, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels.values, dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.user_features[idx], self.offer_ids[idx], self.cat_features[idx], self.labels[idx]\n",
    "\n",
    "train_dataset = CustomDataset(X_train[user_features_cols], X_train[offer_id_col], X_train[cat_features_cols], y_train)\n",
    "test_dataset = CustomDataset(X_test[user_features_cols], X_test[offer_id_col], X_test[cat_features_cols], y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 770164 entries, 0 to 770163\n",
      "Columns: 343 entries, id3 to f41_ratio\n",
      "dtypes: Int16(64), Int32(9), Int8(14), bool(93), category(11), float32(150), int64(1), object(1)\n",
      "memory usage: 723.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTripleTower(nn.Module):\n",
    "    def __init__(self, num_user_features, num_offers, num_cat_features, \n",
    "                 embedding_dim=16, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        \n",
    "        # User Tower\n",
    "        self.user_tower = nn.Sequential(\n",
    "            nn.Linear(num_user_features, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, 32),\n",
    "            nn.BatchNorm1d(32)\n",
    "        )\n",
    "        \n",
    "        # Offer Tower\n",
    "        self.offer_embedding = nn.Embedding(num_offers, embedding_dim)\n",
    "        self.offer_tower = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(32, 32),\n",
    "            nn.BatchNorm1d(32)\n",
    "        )\n",
    "        \n",
    "        self.interaction_tower = nn.Sequential(\n",
    "            nn.Linear(num_cat_features, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, 32),\n",
    "            nn.BatchNorm1d(32)\n",
    "        )\n",
    "        \n",
    "        # Gating\n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Linear(32 * 3, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 3),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "        # Final prediction\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Linear(32 * 3, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, user_features, offer_ids, cat_features):\n",
    "        # Get embeddings from each tower\n",
    "        user_emb = self.user_tower(user_features)\n",
    "        \n",
    "        offer_emb = self.offer_embedding(offer_ids)\n",
    "        offer_emb = self.offer_tower(offer_emb)\n",
    "        \n",
    "        interaction_emb = self.interaction_tower(cat_features)\n",
    "        \n",
    "        # Gating\n",
    "        combined = torch.cat([user_emb, offer_emb, interaction_emb], dim=1)\n",
    "        gates = self.gate(combined)\n",
    "        \n",
    "        # Apply gates\n",
    "        weighted_user = user_emb * gates[:, 0:1]\n",
    "        weighted_offer = offer_emb * gates[:, 1:2]\n",
    "        weighted_interaction = interaction_emb * gates[:, 2:3]\n",
    "        \n",
    "        # Combine and predict\n",
    "        final_input = torch.cat([weighted_user, weighted_offer, weighted_interaction], dim=1)\n",
    "        output = self.final(final_input)\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "num_user_features = len(user_features_cols)\n",
    "num_cat_features = len(cat_features_cols)\n",
    "model = SimpleTripleTower(num_user_features, num_offers, num_cat_features)\n",
    "model.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)  # Reduced learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.1434, Val Loss: 0.1092\n",
      "Epoch 2/10, Train Loss: 0.1095, Val Loss: 0.1029\n",
      "Epoch 3/10, Train Loss: 0.1045, Val Loss: 0.0985\n",
      "Epoch 4/10, Train Loss: 0.1011, Val Loss: 0.0960\n",
      "Epoch 5/10, Train Loss: 0.0987, Val Loss: 0.0950\n",
      "Epoch 6/10, Train Loss: 0.0968, Val Loss: 0.0942\n",
      "Epoch 7/10, Train Loss: 0.0953, Val Loss: 0.0908\n",
      "Epoch 8/10, Train Loss: 0.0943, Val Loss: 0.0935\n",
      "Epoch 9/10, Train Loss: 0.0933, Val Loss: 0.0896\n",
      "Epoch 10/10, Train Loss: 0.0924, Val Loss: 0.0881\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for user, offer, cat, label in train_loader:\n",
    "        user, offer, cat, label = user.to(device), offer.to(device), cat.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(user, offer, cat)\n",
    "        loss = criterion(output.squeeze(), label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for user, offer, cat, label in test_loader:\n",
    "            user, offer, cat, label = user.to(device), offer.to(device), cat.to(device), label.to(device)\n",
    "            output = model(user, offer, cat)\n",
    "            val_loss += criterion(output.squeeze(), label).item()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(test_loader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@7 on validation set: 0.7407\n",
      "Number of users evaluated: 2054\n",
      "AP distribution - Min: 0.1429, Max: 1.0000, Median: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# MAP@7 Evaluation\n",
    "def calculate_map_at_k(model, X_test, y_test, user_test, user_features_cols, offer_id_col, cat_features_cols, device, k=7):\n",
    "    \"\"\"Calculate Mean Average Precision at K for each user\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Create a dataframe with predictions\n",
    "    test_df = pd.DataFrame({\n",
    "        'user_id': user_test.values,\n",
    "        'true_label': y_test.values\n",
    "    })\n",
    "    \n",
    "    # Get model predictions\n",
    "    with torch.no_grad():\n",
    "        user_feats = torch.tensor(X_test[user_features_cols].values, dtype=torch.float32).to(device)\n",
    "        offer_ids = torch.tensor(X_test[offer_id_col].values, dtype=torch.long).to(device)\n",
    "        cat_feats = torch.tensor(X_test[cat_features_cols].values, dtype=torch.float32).to(device)\n",
    "        \n",
    "        outputs = model(user_feats, offer_ids, cat_feats)\n",
    "        predictions = torch.sigmoid(outputs.squeeze()).cpu().numpy()\n",
    "    \n",
    "    test_df['prediction'] = predictions\n",
    "    test_df['offer_id'] = X_test[offer_id_col].values\n",
    "    \n",
    "    # Calculate MAP@7 for each user\n",
    "    user_aps = []\n",
    "    \n",
    "    for user_id, user_data in test_df.groupby('user_id'):\n",
    "        # Sort by prediction score (descending)\n",
    "        user_data = user_data.sort_values('prediction', ascending=False)\n",
    "        \n",
    "        # Get top k predictions\n",
    "        top_k = user_data.head(k)\n",
    "        \n",
    "        # Calculate average precision\n",
    "        relevant_items = top_k['true_label'].values\n",
    "        \n",
    "        if relevant_items.sum() == 0:\n",
    "            # No relevant items for this user\n",
    "            continue\n",
    "        \n",
    "        precision_at_i = []\n",
    "        num_relevant = 0\n",
    "        \n",
    "        for i, is_relevant in enumerate(relevant_items):\n",
    "            if is_relevant == 1:\n",
    "                num_relevant += 1\n",
    "                precision_at_i.append(num_relevant / (i + 1))\n",
    "        \n",
    "        if len(precision_at_i) > 0:\n",
    "            ap = np.mean(precision_at_i)\n",
    "            user_aps.append(ap)\n",
    "    \n",
    "    map_score = np.mean(user_aps) if user_aps else 0.0\n",
    "    return map_score, user_aps\n",
    "\n",
    "# Calculate MAP@7\n",
    "map7_score, all_aps = calculate_map_at_k(\n",
    "    model, X_test, y_test, user_test, \n",
    "    user_features_cols, offer_id_col, cat_features_cols, \n",
    "    device, k=7\n",
    ")\n",
    "print(f\"MAP@7 on validation set: {map7_score:.4f}\")\n",
    "print(f\"Number of users evaluated: {len(all_aps)}\")\n",
    "print(f\"AP distribution - Min: {np.min(all_aps):.4f}, Max: {np.max(all_aps):.4f}, Median: {np.median(all_aps):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
